# hackathon2024_2
Задача «Классификация эмоций в текстовых расшифровках голосовых сообщений»
Цель
Определить настроение говорящего, анализируя текстовую расшифровку его голосового сообщения.

Материалы
Текстовые расшифровки голосовых сообщений, размеченные по категориям эмоций (формат .xlsx и .csv)
Предоставляются наборы текстов, полученных из реальных голосовых сообщений. Эти данные содержат тексты, уже аннотированные по различным эмоциональным категориям, таким как счастье, грусть, гнев и другие. При необходимости вы можете расширить датасет (данными из открытых источников, синтетическими данными).

Структура:
\.venv - окружение

emotions.csv - сырой набор данных

data.py - скрипт для предварительной обработке данных. Этот скрипт выполняет предобработку текста из файла emotions.csv, очищает его от ненужных символов, стоп-слов и лемматизирует, а затем сохраняет обработанные данные в новый файл processed_emotions.csv

processed_emotions.csv - файл с обработанными данными

syn.py - скрипт для аугментации данных. Этот скрипт выполняет агментацию данных для задач обработки естественного языка (NLP). Он использует метод обратного перевода (back translation) для генерации новых текстов на основе исходных данных

augmented_emotions.csv - набор данных после аугментации

augmenter.py - скрипт для второй аугментации данных. Этот скрипт выполняет двойную аугментацию текстов для создания расширенного набора данных, используя замену слов синонимами.

augmented_data.csv - набор данных после двойной аугментации

TrFXLMRobertaFor_SVM092.py - итоговый скрипт. Этот скрипт выполняет обучение модели классификации эмоций на текстовых данных, используя модель XLM-RoBERTa для генерации эмбеддингов текстов и классификатор SVM (метод опорных векторов) для классификации. В данном скрипте мы используем для обучения 2 набора данных: emotions.csv и augmented_data.csv

svm_emotion_model.pkl - Обученная модель

EDA.ipynb - файл с разведочным анализом данных

Описание:
Первоначально набор данных emotions.csv  подвергся предварительной обработке с помощью скрипта data.py. Этот скрипт выполняет предобработку текста из файла emotions.csv, очищает его от ненужных символов, стоп-слов и лемматизирует (приводит к начальной форме, для этого был немного видоизменен код самой библиотеке, если вы не будете использовать наше окружение, то необходимо скачать файл base.py и заменить его в папке programs\Anaconda\Lib\site-packages\pymorphy2\units\base.py),  затем обработанные данные ,были сохранены в новый файл processed_emotions.csv
Далее мы запустили скрипт syn.py. Этот скрипт выполняет агментацию данных для задач обработки естественного языка (NLP). Он использует метод обратного перевода (back translation) для генерации новых текстов на основе исходных данных. Данные были сохранены в augmented_emotions.csv .
После нескольких экспериментов, мы поняли, что данных нехватает и необходимо вторая аугментация.
Скрипт augmenter.py произвел вторую аугментацию данных. Этот скрипт выполняет двойную аугментацию текстов для создания расширенного набора данных, используя замену слов синонимами.
Полученные данные были сохранены в augmented_data.csv.
TrFXLMRobertaFor_SVM092.py - итоговый скрипт. Этот скрипт выполняет обучение модели классификации эмоций на текстовых данных, используя модель XLM-RoBERTa для генерации эмбеддингов текстов и классификатор SVM (метод опорных векторов) для классификации. В данном скрипте мы используем для обучения 2 набора данных: emotions.csv и augmented_data.csv
Эксперименты показали, что использование для классификации только модели Roberta занимает много времени (более 9 часов) и дает низкий результат (менее 0,5 rocauc). Так как данных было ограниченное количество, было принято решение совместить этот метод с методом SVM, этот метод также требует значительного количества данных, но гораздо меньше, чем Roberta .  Применение метода SVM  показало максимальный результат при выборе ядра linear.  Использование эмбеддингов XLM-RoBERTa (векторных представлений текста) обеспечивает высокую семантическую информативность, эти эмбеддинги уже расположены в пространстве признаков таким образом, что данные становятся линейно разделимыми. Это сделало линейное ядро подходящим выбором.
Линейное ядро выполняет классификацию в исходном пространстве признаков, что снижает вычислительные затраты и уменьшает вероятность переобучения при наличии ограниченного объема данных.
Более сложные ядра (например, RBF или полиномиальное) могут избыточно усложнять модель, особенно если данные уже линейно разделимы. Другие ядра по сравнению с linear показали более низкие результаты. 
Итог: svm_emotion_model.pkl - Обученная модель
